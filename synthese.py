"""
Module de synth√®se des contributions avec IA locale (Ollama).
Design √©pur√© fond blanc avec contours noirs
Streaming pour affichage en temps r√©el
"""

import tkinter as tk
from tkinter import messagebox
import ttkbootstrap as ttk
from ttkbootstrap.scrolled import ScrolledText
import threading
import requests

from database import get_contributions, get_consultation_details

# Configuration Ollama
OLLAMA_URL = "http://localhost:11434/api/generate"
DEFAULT_MODEL = "qwen2:0.5b"  # Mod√®le l√©ger et rapide

# Configuration des styles
FONT_TITLE = ("Segoe UI", 20, "bold")
FONT_SUBTITLE = ("Segoe UI", 11)
FONT_NORMAL = ("Segoe UI", 11)
FONT_SMALL = ("Segoe UI", 10)


def check_ollama_running():
    """V√©rifie si Ollama est en cours d'ex√©cution."""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=2)
        return response.status_code == 200
    except:
        return False


def get_available_models():
    """R√©cup√®re la liste des mod√®les disponibles dans Ollama."""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            data = response.json()
            return [model["name"] for model in data.get("models", [])]
    except:
        pass
    return []


def generate_synthesis_stream(contributions_text, question, model, text_widget, status_var, btn, win):
    """
    G√©n√®re une synth√®se avec streaming (affichage en temps r√©el).
    """
    prompt = f"""Tu es un expert en analyse et synth√®se de contributions citoyennes.

CONTEXTE:
Une consultation publique a √©t√© organis√©e sur le th√®me suivant : "{question}"

CONTRIBUTIONS DES PARTICIPANTS:
{contributions_text}

MISSION:
Analyse ces contributions et produis une synth√®se structur√©e qui:
1. Identifie les TH√àMES PRINCIPAUX qui ressortent des contributions
2. Pr√©sente les POINTS DE CONSENSUS (id√©es partag√©es par plusieurs)
3. Rel√®ve les DIVERGENCES ou points de vue oppos√©s
4. Propose des RECOMMANDATIONS bas√©es sur l'ensemble des avis

FORMAT DE R√âPONSE:
Utilise des titres clairs et des puces pour structurer ta r√©ponse.
Sois objectif et repr√©sente fid√®lement toutes les opinions exprim√©es.
√âcris en fran√ßais. Sois concis.
"""

    try:
        response = requests.post(
            OLLAMA_URL,
            json={
                "model": model,
                "prompt": prompt,
                "stream": True,
                "options": {
                    "temperature": 0.7,
                    "num_predict": 1500
                }
            },
            stream=True,
            timeout=300
        )
        
        if response.status_code == 200:
            # Effacer le texte d'attente
            def clear_text():
                text_widget.config(state="normal")
                text_widget.delete("1.0", "end")
            win.after(0, clear_text)
            
            # Lire le stream
            for line in response.iter_lines():
                if line:
                    try:
                        import json
                        data = json.loads(line)
                        chunk = data.get("response", "")
                        if chunk:
                            def append_text(t=chunk):
                                text_widget.config(state="normal")
                                text_widget.insert("end", t)
                                text_widget.see("end")
                                text_widget.config(state="disabled")
                            win.after(0, append_text)
                        
                        # V√©rifier si c'est fini
                        if data.get("done", False):
                            break
                    except:
                        pass
            
            def on_complete():
                status_var.set("Synth√®se termin√©e")
                btn.config(state="normal")
            win.after(0, on_complete)
            
        else:
            def on_error():
                text_widget.config(state="normal")
                text_widget.delete("1.0", "end")
                text_widget.insert("1.0", f"Erreur Ollama: {response.status_code}")
                text_widget.config(state="disabled")
                status_var.set("Erreur")
                btn.config(state="normal")
            win.after(0, on_error)
            
    except requests.exceptions.ConnectionError:
        def on_error():
            text_widget.config(state="normal")
            text_widget.delete("1.0", "end")
            text_widget.insert("1.0", "Impossible de se connecter √† Ollama. V√©rifiez qu'il est lanc√©.")
            text_widget.config(state="disabled")
            status_var.set("Erreur de connexion")
            btn.config(state="normal")
        win.after(0, on_error)
    except Exception as e:
        def on_error():
            text_widget.config(state="normal")
            text_widget.delete("1.0", "end")
            text_widget.insert("1.0", f"Erreur: {str(e)}")
            text_widget.config(state="disabled")
            status_var.set("Erreur")
            btn.config(state="normal")
        win.after(0, on_error)


def afficher_synthese(root, consultation_id, consultation_nom):
    """Affiche la fen√™tre de synth√®se pour une consultation."""
    
    # R√©cup√©rer les contributions
    contributions = get_contributions(consultation_id)
    details = get_consultation_details(consultation_id)
    
    if not contributions:
        messagebox.showinfo(
            "Aucune contribution",
            "Il n'y a pas encore de contributions pour cette consultation."
        )
        return
    
    # Cr√©er la fen√™tre
    win = ttk.Toplevel(root)
    win.title(f"Synth√®se - {consultation_nom}")
    win.geometry("850x650")
    win.resizable(True, True)
    win.configure(bg="white")
    
    # Centrer la fen√™tre
    win.place_window_center()
    
    # Rendre modale
    win.transient(root)
    win.grab_set()
    
    # Container principal
    main_frame = ttk.Frame(win, bootstyle="light", padding=25)
    main_frame.pack(fill="both", expand=True)
    
    # Header
    header_frame = ttk.Frame(main_frame, bootstyle="light")
    header_frame.pack(fill="x", pady=(0, 15))
    
    ttk.Label(
        header_frame,
        text="Synth√®se IA",
        font=FONT_TITLE,
        foreground="black"
    ).pack(side="left")
    
    ttk.Button(
        header_frame,
        text="Fermer",
        bootstyle="secondary-link",
        command=win.destroy
    ).pack(side="right")
    
    # Info consultation
    ttk.Label(
        main_frame,
        text=consultation_nom,
        font=FONT_SUBTITLE,
        foreground="gray",
        wraplength=750
    ).pack(anchor="w")
    
    nb_contributions = len(contributions)
    ttk.Label(
        main_frame,
        text=f"{nb_contributions} contribution{'s' if nb_contributions > 1 else ''} √† analyser",
        font=FONT_SMALL,
        foreground="gray"
    ).pack(anchor="w", pady=(5, 15))
    
    # Ligne de s√©paration
    sep = ttk.Frame(main_frame, height=1, bootstyle="dark")
    sep.pack(fill="x", pady=(0, 15))
    
    # S√©lection du mod√®le
    model_frame = ttk.Frame(main_frame, bootstyle="light")
    model_frame.pack(fill="x", pady=(0, 15))
    
    ttk.Label(
        model_frame,
        text="Mod√®le :",
        font=FONT_NORMAL,
        foreground="black"
    ).pack(side="left", padx=(0, 10))
    
    models = get_available_models()
    if not models:
        models = [DEFAULT_MODEL]
    
    model_var = ttk.StringVar(value=models[0] if models else DEFAULT_MODEL)
    
    # Combobox avec bordure
    combo_border = ttk.Frame(model_frame, bootstyle="dark", padding=1)
    combo_border.pack(side="left")
    
    model_combo = ttk.Combobox(
        combo_border,
        textvariable=model_var,
        values=models,
        state="readonly",
        width=25,
        font=FONT_NORMAL
    )
    model_combo.pack()
    
    # Bouton g√©n√©rer
    btn_generer = ttk.Button(
        model_frame,
        text="G√©n√©rer la synth√®se",
        bootstyle="dark",
        padding=(20, 8)
    )
    btn_generer.pack(side="right")
    
    # Indicateur de statut
    status_var = ttk.StringVar(value="")
    status_label = ttk.Label(
        main_frame,
        textvariable=status_var,
        font=FONT_SMALL,
        foreground="gray"
    )
    status_label.pack(anchor="w", pady=(0, 10))
    
    # Zone de r√©sultat avec bordure
    result_border = ttk.Frame(main_frame, bootstyle="dark", padding=1)
    result_border.pack(fill="both", expand=True)
    
    result_text = ScrolledText(result_border, autohide=True)
    result_text.pack(fill="both", expand=True)
    result_text.text.config(
        font=("Consolas", 10),
        wrap="word",
        state="disabled",
        padx=15,
        pady=15,
        bg="white"
    )
    
    # Fonction de g√©n√©ration
    def lancer_synthese():
        if not check_ollama_running():
            messagebox.showerror(
                "Ollama non disponible",
                "Ollama n'est pas en cours d'ex√©cution.\n\n"
                "Pour l'installer :\n"
                "1. T√©l√©chargez sur https://ollama.ai\n"
                "2. Installez et lancez Ollama\n"
                "3. Ex√©cutez : ollama pull mistral\n"
                "4. R√©essayez"
            )
            return
        
        # Pr√©parer le texte
        contributions_text = "\n\n---\n\n".join([
            f"Contribution {i+1}:\n{texte}" 
            for i, (_, texte) in enumerate(contributions)
        ])
        
        question = details[1] if details else consultation_nom
        model = model_var.get()
        
        # UI loading
        btn_generer.config(state="disabled")
        status_var.set("G√©n√©ration en cours... (la r√©ponse s'affiche en temps r√©el)")
        
        result_text.text.config(state="normal")
        result_text.text.delete("1.0", "end")
        result_text.text.insert("1.0", "Connexion au mod√®le IA...\n")
        result_text.text.config(state="disabled")
        
        # Lancer en streaming
        thread = threading.Thread(
            target=generate_synthesis_stream,
            args=(contributions_text, question, model, result_text.text, status_var, btn_generer, win)
        )
        thread.daemon = True
        thread.start()
    
    btn_generer.config(command=lancer_synthese)
    
    # Note sur la performance
    perf_label = ttk.Label(
        main_frame,
        text="üí° Astuce : Pour une synth√®se plus rapide, utilisez un mod√®le l√©ger comme 'phi3' ou 'llama3.2:1b'",
        font=FONT_SMALL,
        foreground="gray"
    )
    perf_label.pack(anchor="w", pady=(10, 0))
